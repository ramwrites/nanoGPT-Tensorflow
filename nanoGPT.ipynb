{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Cofig"
      ],
      "metadata": {
        "id": "hbrrelagTmy0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L_YVET7-TgQH"
      },
      "outputs": [],
      "source": [
        "cfg = {\n",
        "\"block_size\" : 256,\n",
        "\"batch_size\": 64,\n",
        "\"dropout\": 0.2,\n",
        "\"n_embd\" : 384,\n",
        "\"n_heads\" : 6,\n",
        "\"vocab_size\": 65,\n",
        "\"n_layers\": 6,\n",
        "\"head_dim\": int(384/6),\n",
        "\"learning_rate\" : 3e-4,\n",
        "\"max_iters\": 5000,\n",
        "\"eval_interval\": 500,\n",
        "\"eval_iters\": 200\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "8fyv_HrATvZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os"
      ],
      "metadata": {
        "id": "X5ZkrWxRTqjc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ovaJl3_aRfR",
        "outputId": "a6851753-4af2-4c37-ab2d-0d5579a11261"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Text File"
      ],
      "metadata": {
        "id": "DXpG-jyPT6VH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/nano GPT/tinyshakespeare.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "uMW0yNdhT2NR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFHo2qM-T9nh",
        "outputId": "4f7f64eb-a44b-4519-d2e5-ad5db599c416"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlOCbS2qUAcB",
        "outputId": "92399a94-de8e-400b-dad2-cc60006f752a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))"
      ],
      "metadata": {
        "id": "x9Llhe3EUDB5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GidYKGb_UFer",
        "outputId": "ddd9b6c8-f4c4-48d0-a1f9-6ef3d0a6d0e4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\".join(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Eizm5yxIUHsN",
        "outputId": "1892bbcc-c773-4fd0-c4fe-2a7bc2bae0a1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(chars)\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjgh2HyyUJ94",
        "outputId": "54c86579-25c1-4d08-93aa-b53e3298ba6e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TokenID"
      ],
      "metadata": {
        "id": "pp5OU0zKUOMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {ch:i for i, ch in enumerate(chars)} # chars to tokenID mapping\n",
        "itos = {i:ch for i, ch in enumerate(chars)} # tokenID to chars mapping\n",
        "\n",
        "# given a string it converts every char to tokenID and returns a list\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "# given a list of tokenID's it converts it back to string and returns it\n",
        "decode = lambda l: ''.join([itos[i] for i in l])"
      ],
      "metadata": {
        "id": "Lq6zmivlUMi9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode('hello world')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUThS8R0US8-",
        "outputId": "c521d6ad-8fba-4ba9-f21b-c7921e3d8d9d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[46, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode([46, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Jot3X3SKUVZM",
        "outputId": "6976c441-81e5-4dfc-e91d-5a60c6bd4886"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello world'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Val Split"
      ],
      "metadata": {
        "id": "2FP9r-d3UanR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = tf.convert_to_tensor(encode(text))"
      ],
      "metadata": {
        "id": "T1FKfCMLUYQA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[:100].numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpKfmtxNUfto",
        "outputId": "960746b2-b27c-4a81-f026-1b94f5f60a61"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43,\n",
              "       44, 53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39,\n",
              "       52, 63,  1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1,\n",
              "       51, 43,  1, 57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31,\n",
              "       54, 43, 39, 49,  6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56,\n",
              "       57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 37, 53, 59],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9* len(data))\n",
        "train = data[:n]\n",
        "val = data[n:]"
      ],
      "metadata": {
        "id": "LkLxF8F_Uh0h"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train))\n",
        "print(len(val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVJeKP2XUkFE",
        "outputId": "78e04383-b6b6-44ba-9fd9-dbcbb33d878d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1003854\n",
            "111540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading"
      ],
      "metadata": {
        "id": "am9gBQfvUoBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split):\n",
        "    data = train if split == 'train' else val\n",
        "    # this generates the start index for each batch from [0, len-blocksize]\n",
        "    ix = np.random.randint(low = 0, high=len(data)-cfg['block_size'], size = cfg['batch_size'])\n",
        "    # this creates the x and y from the start index\n",
        "    x = tf.stack([data[i: i+cfg['block_size']] for i in ix], axis = 0)\n",
        "    y = tf.stack([data[i+1: i+cfg['block_size']+1] for i in ix], axis = 0)\n",
        "\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "U3u2ih2YUmZi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = get_batch('train')"
      ],
      "metadata": {
        "id": "UkSTd72EUs6j"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFHhEdcOUvXA",
        "outputId": "2604755a-3dd3-4a5b-8c5c-4307926a870c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 256), dtype=int32, numpy=\n",
              "array([[52, 58, 10, ..., 53, 59, 45],\n",
              "       [ 1, 39,  1, ..., 47, 53, 52],\n",
              "       [47, 57,  1, ..., 52, 53, 61],\n",
              "       ...,\n",
              "       [59, 41, 41, ...,  1, 51, 63],\n",
              "       [ 1, 51, 39, ...,  1, 59, 57],\n",
              "       [ 1, 46, 47, ..., 17, 26, 17]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQj9y7UrUyX8",
        "outputId": "bf3a6856-9760-41e5-f476-0ee3867f4554"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 256), dtype=int32, numpy=\n",
              "array([[58, 10,  0, ..., 59, 45, 46],\n",
              "       [39,  1, 41, ..., 53, 52,  6],\n",
              "       [57,  1, 52, ..., 53, 61,  1],\n",
              "       ...,\n",
              "       [41, 41, 43, ..., 51, 63, 57],\n",
              "       [51, 39, 49, ..., 59, 57,  2],\n",
              "       [46, 47, 57, ..., 26, 17, 26]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self Attention Block"
      ],
      "metadata": {
        "id": "wEalw0Q6U1I4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(tf.Module):\n",
        "    # one head of self attention\n",
        "    def __init__(self, head_size, name = None):\n",
        "        super().__init__(name = name)\n",
        "        self.head_size = head_size\n",
        "        self.key = tf.keras.layers.Dense(head_size, use_bias=False)\n",
        "        self.query = tf.keras.layers.Dense(head_size, use_bias=False)\n",
        "        self.value = tf.keras.layers.Dense(head_size, use_bias=False)\n",
        "        # this creates a lower triangle matrix with the numbers above the diagonal set to 0 and trianable = False\n",
        "        self.tril = tf.linalg.band_part(tf.Variable(tf.ones((cfg['block_size'], cfg['block_size'])),\n",
        "                                                    trainable=False),\n",
        "                                        num_lower=-1,\n",
        "                                        num_upper=0)\n",
        "        self.dropout = tf.keras.layers.Dropout(cfg['dropout'])\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # Input shape (batch, time_step, channels)\n",
        "        # Output shape (batch, time_step, num_heads)\n",
        "\n",
        "        B,T,C = x.shape\n",
        "\n",
        "        # key, query, value\n",
        "        k = self.key(x) # (B,T,hs)\n",
        "        q = self.query(x) # (B,T,hs)\n",
        "        v = self.value(x) # (B,T,hs)\n",
        "\n",
        "        # attention scores\n",
        "        # attenion scores using dot product of query and keys and scaling it\n",
        "        attention_scores = q @ tf.transpose(k, perm=[0, 2, 1]) * k.shape[-1]**-0.5 # (B,T,hs) @ (B,hs,T) --> (B,T,T)\n",
        "        # masking the attention scores of future tokens\n",
        "        mask = self.tril[:T, :T]\n",
        "        attention_scores = tf.where(mask == 0, tf.fill(attention_scores.shape, float('-inf')), attention_scores) # (B,T,T)\n",
        "        attention_weights = tf.nn.softmax(attention_scores, axis = -1)\n",
        "        attention_weights = self.dropout(attention_weights)\n",
        "        # weighted aggregation of values\n",
        "        out = attention_weights @ v # (B,T,T) @ (B,T,hs) --> (B,T,hs)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "sOG8laLJUy9t"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MultiHeadAttention"
      ],
      "metadata": {
        "id": "uuHLOhI4VY2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, n_heads, n_embd, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.n_embd = n_embd # 384\n",
        "        self.num_heads = n_heads  # 6\n",
        "        self.head_dim = int(n_embd/n_heads) # 384/6 = 64\n",
        "        self.W_key = tf.keras.layers.Dense(n_embd, use_bias=False)\n",
        "        self.W_query = tf.keras.layers.Dense(n_embd, use_bias=False)\n",
        "        self.W_value = tf.keras.layers.Dense(n_embd, use_bias=False)\n",
        "        self.dropout = tf.keras.layers.Dropout(cfg['dropout'])\n",
        "        self.tril = tf.linalg.band_part(tf.Variable(tf.ones((cfg['block_size'], cfg['block_size'])),\n",
        "                                                    trainable=False),\n",
        "                                        num_lower=-1,\n",
        "                                        num_upper=0)\n",
        "        self.out_proj = tf.keras.layers.Dense(n_embd)\n",
        "\n",
        "    def call(self, x, training = True):\n",
        "        b, num_tokens, embd_dim = x.shape\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = tf.reshape(keys, (b, num_tokens, self.num_heads, self.head_dim))\n",
        "        queries = tf.reshape(queries, (b, num_tokens, self.num_heads, self.head_dim))\n",
        "        values = tf.reshape(values, (b, num_tokens, self.num_heads, self.head_dim))\n",
        "\n",
        "        keys = tf.transpose(keys, perm=[0,2,1,3])\n",
        "        queries = tf.transpose(queries, perm=[0,2,1,3])\n",
        "        values = tf.transpose(values, perm=[0,2,1,3])\n",
        "\n",
        "        attention_scores = queries @ tf.transpose(keys, perm=[0, 1, 3, 2]) * keys.shape[-1]**-0.5\n",
        "        mask = self.tril[:num_tokens, :num_tokens]\n",
        "\n",
        "        attention_scores = tf.where(mask == 0, tf.fill(attention_scores.shape, float('-inf')), attention_scores)\n",
        "\n",
        "        attention_weights = tf.nn.softmax(attention_scores, axis = -1)\n",
        "        attention_weights = self.dropout(attention_weights, training = training)\n",
        "\n",
        "        context_vec = tf.transpose(attention_weights @ values, perm = [0,2,1,3])\n",
        "\n",
        "        context_vec = tf.reshape(context_vec, (b, num_tokens, self.n_embd))\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "thI2oDTbVXpl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPT Model"
      ],
      "metadata": {
        "id": "nqbExprGVoDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.net = tf.keras.Sequential(\n",
        "            [\n",
        "                tf.keras.layers.Dense(cfg['n_embd']*4),\n",
        "                tf.keras.layers.ReLU(),\n",
        "                tf.keras.layers.Dense(cfg['n_embd']),\n",
        "            ]\n",
        "        )\n",
        "    def call(self, x, training = True):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "5wLijEnqVbNW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.mha = MultiHeadAttention(n_heads=cfg['n_heads'], n_embd=cfg['n_embd'])\n",
        "        self.feed = FeedForward(cfg)\n",
        "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.drop_shortcut = tf.keras.layers.Dropout(cfg['dropout'])\n",
        "    def call(self, x, training = True):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.mha(x)\n",
        "        x = self.drop_shortcut(x, training = training)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.feed(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "AlloFHjmVru8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_loss(model):\n",
        "    out = []\n",
        "    training = False\n",
        "    for split in ['train', 'val']:\n",
        "        losses = []\n",
        "        for k in range(cfg['eval_iters']):\n",
        "            x, y = get_batch(split)\n",
        "            logits, loss = model(x,y, training = training)\n",
        "            losses.append(loss.numpy())\n",
        "        out.append(tf.reduce_mean(losses))\n",
        "    return tf.convert_to_tensor(out)"
      ],
      "metadata": {
        "id": "F9bR0KNrVuUY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(targets, logits):\n",
        "    loss_values = tf.keras.losses.sparse_categorical_crossentropy(targets, logits, from_logits=True)\n",
        "    return tf.reduce_mean(loss_values)"
      ],
      "metadata": {
        "id": "9lacF8KVV3ZS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(tf.keras.models.Model):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = tf.keras.layers.Embedding(input_dim=cfg['vocab_size'], output_dim=cfg['n_embd'])\n",
        "        self.pos_emb = tf.keras.layers.Embedding(input_dim=cfg['block_size'], output_dim=cfg['n_embd'])\n",
        "        self.drop = tf.keras.layers.Dropout(cfg['dropout'])\n",
        "        self.trf_blocks = tf.keras.Sequential(\n",
        "            [TransformerBlock(cfg) for _ in range(cfg['n_layers'])]\n",
        "        )\n",
        "        self.final_norm = tf.keras.layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.out_head = tf.keras.layers.Dense(cfg['vocab_size'], use_bias=False)\n",
        "    def call(self, in_idx, targets=None, training = True):\n",
        "        batch, seq_len = in_idx.shape\n",
        "        tok_emb = self.tok_emb(in_idx)\n",
        "        pos_emb = self.pos_emb(tf.range(seq_len))\n",
        "        x = tok_emb + pos_emb\n",
        "        x = self.drop(x, training = training)\n",
        "        x = self.trf_blocks(x, training = training)\n",
        "        # self.final_norm.gamma.trainable = training\n",
        "        # self.final_norm.beta.trainable = training\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x) # (b, num_tokens, vocab_size)\n",
        "\n",
        "        if targets == None:\n",
        "            loss = None\n",
        "        else:\n",
        "            loss = loss_func(targets, logits)\n",
        "        return logits, loss"
      ],
      "metadata": {
        "id": "iAhqR8rmV5wL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, txt, max_new_tokens):\n",
        "  idx = tf.convert_to_tensor([encode(txt)])\n",
        "  for i in range(max_new_tokens):\n",
        "      block_idx = idx[:, -cfg['block_size']:]\n",
        "      logits, loss = model(block_idx, training=False)\n",
        "      logits = logits[:, -1, :]\n",
        "      probas = tf.nn.softmax(logits, axis = -1)\n",
        "      idx_next = np.argmax(probas, axis = -1, keepdims=True)\n",
        "      idx = tf.concat([idx, idx_next], axis = -1)\n",
        "\n",
        "  decoded_text = decode(np.squeeze(idx.numpy()).tolist())\n",
        "  print(decoded_text)"
      ],
      "metadata": {
        "id": "nsborvFvt1Ot"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nano_gpt = GPTModel(cfg)"
      ],
      "metadata": {
        "id": "cMTeLi8_V_vV"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "Jnocec4fWGqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.AdamW(learning_rate=cfg['learning_rate'])"
      ],
      "metadata": {
        "id": "aq58jwDIWECs"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nano_gpt(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "I-fs13iTIvP9",
        "outputId": "04bd5437-2613-484b-808d-85151966c3ae"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(64, 256, 65), dtype=float32, numpy=\n",
              " array([[[-0.20846345, -1.9429071 ,  1.3011606 , ...,  0.78615093,\n",
              "          -1.0147915 , -0.6277273 ],\n",
              "         [ 0.3492674 , -1.5829298 ,  2.2471912 , ...,  0.9334457 ,\n",
              "           0.3026073 ,  1.1786331 ],\n",
              "         [ 1.329802  , -2.1322942 ,  3.784091  , ..., -0.1127113 ,\n",
              "          -0.03692227, -1.1613263 ],\n",
              "         ...,\n",
              "         [-0.88985485,  0.23510765,  0.21676378, ...,  1.2272862 ,\n",
              "          -0.06108657,  0.7893808 ],\n",
              "         [-0.02013638,  0.09895454,  0.69079965, ...,  1.1361108 ,\n",
              "           0.14594793,  0.6558433 ],\n",
              "         [-0.32299265, -0.51938426,  0.2724907 , ...,  0.55434775,\n",
              "          -0.40204123, -0.1493415 ]],\n",
              " \n",
              "        [[-2.26906   , -1.0781363 , -0.07381792, ...,  2.152628  ,\n",
              "          -0.1096975 ,  0.801946  ],\n",
              "         [-0.1483921 , -1.6223848 , -1.2839822 , ...,  2.412289  ,\n",
              "           0.70111674, -0.25935566],\n",
              "         [-0.3733255 , -2.5930138 , -0.23633076, ...,  1.7961799 ,\n",
              "           0.2627119 , -0.2841192 ],\n",
              "         ...,\n",
              "         [ 0.6881539 , -0.26455396,  0.47761613, ...,  1.3824914 ,\n",
              "          -0.9428628 , -0.5656165 ],\n",
              "         [-0.5391379 , -0.93328786, -0.2795516 , ...,  2.330987  ,\n",
              "           0.3870178 , -0.672385  ],\n",
              "         [-1.6064049 , -1.6256218 ,  1.7113048 , ...,  2.1965992 ,\n",
              "           0.12836799, -0.5217942 ]],\n",
              " \n",
              "        [[-0.36862552, -1.1574025 , -0.7132698 , ...,  1.7407768 ,\n",
              "          -2.032052  ,  0.42992023],\n",
              "         [-0.33406118, -0.43582183,  0.43668237, ...,  0.12206076,\n",
              "          -3.346352  ,  0.46039632],\n",
              "         [-0.22146723, -2.5418293 ,  0.92552716, ...,  2.5677104 ,\n",
              "          -3.3912883 ,  1.2611278 ],\n",
              "         ...,\n",
              "         [-1.0670413 , -0.9833235 ,  0.42917758, ...,  1.7046893 ,\n",
              "           0.0444438 ,  0.40141425],\n",
              "         [-1.0643388 , -0.9456291 ,  1.6470352 , ...,  2.29988   ,\n",
              "          -0.7089518 , -0.41900912],\n",
              "         [-1.3217837 , -0.04569452,  0.06691172, ...,  1.1441522 ,\n",
              "          -1.2980808 ,  0.7581143 ]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.5417031 , -0.5866426 ,  1.5566813 , ...,  0.5362455 ,\n",
              "          -0.892059  , -0.5929564 ],\n",
              "         [ 0.586923  , -1.2819902 ,  0.3346094 , ..., -0.05663758,\n",
              "           0.6918424 , -0.5313725 ],\n",
              "         [ 0.9945057 , -0.37718308,  2.5096214 , ...,  0.7433567 ,\n",
              "          -0.6379878 ,  1.7071428 ],\n",
              "         ...,\n",
              "         [-0.16442637, -1.2855144 ,  0.7499167 , ...,  2.5034022 ,\n",
              "          -1.2829117 ,  0.23316185],\n",
              "         [ 0.20989119, -1.1920842 ,  1.779066  , ...,  0.9082673 ,\n",
              "           0.21274208, -0.5097957 ],\n",
              "         [ 0.03509997, -1.9543974 ,  2.363136  , ...,  2.2470338 ,\n",
              "          -1.6262741 ,  1.583043  ]],\n",
              " \n",
              "        [[-1.0322928 , -2.1751823 , -0.91061735, ...,  1.2454183 ,\n",
              "           0.13397983,  0.10650566],\n",
              "         [-2.747425  , -0.4962282 ,  2.3480005 , ...,  1.4550356 ,\n",
              "           0.9579178 , -0.8137074 ],\n",
              "         [-0.7077844 , -1.1286945 ,  1.6954433 , ...,  0.72849333,\n",
              "          -0.41848153, -1.5786211 ],\n",
              "         ...,\n",
              "         [-1.0682349 , -0.36442697, -0.07109219, ...,  1.5882226 ,\n",
              "          -1.4029593 ,  0.32272562],\n",
              "         [-1.9750401 , -0.8809974 ,  0.90483886, ...,  1.6655385 ,\n",
              "          -1.1734787 , -0.9320363 ],\n",
              "         [ 0.02982915,  0.40077448, -0.32653102, ...,  0.45868886,\n",
              "           0.26245648,  0.7054279 ]],\n",
              " \n",
              "        [[ 0.40403616, -1.5250632 ,  0.0554198 , ...,  1.6339349 ,\n",
              "          -1.2009149 , -0.16393502],\n",
              "         [ 1.8044293 , -1.8756077 ,  1.024749  , ...,  4.041946  ,\n",
              "          -2.8462367 ,  2.1867876 ],\n",
              "         [-0.4561675 , -1.9084918 ,  1.1577377 , ...,  0.43305767,\n",
              "          -3.184304  ,  0.49459037],\n",
              "         ...,\n",
              "         [-1.5067852 , -1.3200153 , -0.45942813, ...,  1.801235  ,\n",
              "          -1.5139109 ,  1.7484691 ],\n",
              "         [ 0.24632643, -1.0744615 ,  0.070261  , ...,  1.1471546 ,\n",
              "           0.7872728 ,  0.9297667 ],\n",
              "         [-0.8530824 , -1.2169096 ,  1.0851767 , ...,  0.685809  ,\n",
              "          -1.6578523 ,  1.1738551 ]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=5.130213737487793>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/Colab Notebooks/nano GPT'"
      ],
      "metadata": {
        "id": "msrfEadyc5vn"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(cfg['max_iters']):\n",
        "    xb, yb = get_batch('train')\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits, loss = nano_gpt(xb, yb)\n",
        "    gradients = tape.gradient(loss, nano_gpt.trainable_variables)\n",
        "    opt.apply_gradients(zip(gradients, nano_gpt.trainable_variables))\n",
        "    if i%cfg['eval_interval'] == 0:\n",
        "        losses = tf.stop_gradient(estimate_loss(nano_gpt))\n",
        "        print(f'train_loss: {losses[0]} and val_loss: {losses[1]}')\n",
        "        nano_gpt.save(os.path.join(folder_path, f'model{i}.keras'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_bnOWSlWRwy",
        "outputId": "4d1ecbf0-8e66-4d7c-aa95-99b8b2953b53"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss: 5.858647346496582 and val_loss: 5.950787544250488\n",
            "train_loss: 2.3933098316192627 and val_loss: 2.4309804439544678\n",
            "train_loss: 1.9363648891448975 and val_loss: 2.0601372718811035\n",
            "train_loss: 1.6390371322631836 and val_loss: 1.8232166767120361\n",
            "train_loss: 1.5008022785186768 and val_loss: 1.7000079154968262\n",
            "train_loss: 1.4142546653747559 and val_loss: 1.630603313446045\n",
            "train_loss: 1.3522528409957886 and val_loss: 1.5835031270980835\n",
            "train_loss: 1.2997814416885376 and val_loss: 1.5369867086410522\n",
            "train_loss: 1.2568883895874023 and val_loss: 1.515067458152771\n",
            "train_loss: 1.2194623947143555 and val_loss: 1.4995356798171997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nano_gpt.save(os.path.join(folder_path, 'nano_gpt.keras'))"
      ],
      "metadata": {
        "id": "HLy-iKg5b_go"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimate_loss(nano_gpt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r-F68PelaOA",
        "outputId": "2f75c628-cc33-48e1-e5fa-d1ce19992216"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.1928322, 1.493715 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(nano_gpt, 'helen', 700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz2lr6qDrO66",
        "outputId": "86140bc3-6a9b-4999-d831-25aae588d0b1"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "helen the story of the world,\n",
            "Which we shall be so be so much before the storms.\n",
            "\n",
            "KING RICHARD II:\n",
            "What shall I stay thee, and thou shalt be so?\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "The strange of thy son of thy soul that I should stay.\n",
            "\n",
            "KING RICHARD II:\n",
            "So that I have been thee to thy soul have thy love.\n",
            "\n",
            "KING RICHARD III:\n",
            "So will I see thee thy soul I have thy love.\n",
            "\n",
            "KING RICHARD III:\n",
            "So that I have been thy son and my heart.\n",
            "\n",
            "KING RICHARD III:\n",
            "So that I have been thee to thy soul of York.\n",
            "\n",
            "KING RICHARD III:\n",
            "So that I have been thy son and my heart.\n",
            "\n",
            "KING RICHARD III:\n",
            "So that I have been thee to thy soul of York.\n",
            "\n",
            "KING RICHARD III:\n",
            "So that I have been thy son and my heart.\n",
            "\n",
            "KING RICHARD III:\n",
            "So that I have been t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7PVAzYkcvxxB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}